DO: Performance impact of single insert
DO: TEST 3 DIFFERENT TABLES for partitioning and order by
DO: demonstrate SHOW PROCESSLIST

Hello everyone,
In this lesson we'll talk about merge-tree family of CH engines

CH team reccomends using engines of this family pretty much for most tasks
They say those engines are the most advanced engines,
and data replication is possible only with engines from this family

Let's connect to our newly configured ch cluster and try to create a table and a database

CREATE DATABASE merge_tree

I was tempted to create a table like so at first. cool kinds don't read the docs ha
CREATE TABLE merge_tree.event
(
  id UInt64,
  time DateTime,
  type UInt16,
  pokemon_id UInt16
)
ENGINE = MergeTree();
But yeah this will fail

and the reason why it fails TODO

We need to create a table like so
CREATE TABLE merge_tree.event_time_batch
(
  id UInt64,
  time DateTime,
  type UInt16,
  pokemon_id UInt16
)
ENGINE = MergeTree()
PARTITION BY toYYYYMM(time)
ORDER BY (time, id);  -- pay attention to order of fields

CREATE TABLE pokemon.even_time_func_batch
(
  id UInt64,
  time DateTime,
  type UInt16,
  pokemon_id UInt16
)
ENGINE = MergeTree()
PARTITION BY toYYYYMM(time)
ORDER BY (toYYYYMM(time), id);

CREATE TABLE pokemon.event_date_batch
(
  id UInt64,
  time DateTime,
  date Date,
  type UInt16,
  pokemon_id UInt16
)
ENGINE = MergeTree()
PARTITION BY date
ORDER BY (date, id);

CREATE TABLE pokemon.event_0_date_single
(
  id UInt64,
  time DateTime,
  date Date,
  type UInt16,
  pokemon_id UInt16
)
ENGINE = MergeTree()
PARTITION BY date
ORDER BY (date, id);

-- from https://gist.github.com/sanchezzzhak/511fd140e8809857f8f1d84ddb937015
SELECT table, formatReadableSize(size) as size, rows, days, formatReadableSize(avgDaySize) as avgDaySize FROM (
    SELECT
        table,
        sum(bytes) AS size,
        sum(rows) AS rows
    FROM system.parts
    WHERE active
    GROUP BY table
    ORDER BY rows DESC
)

┌─table───────────────────┬─size───────┬─rows─┬
│ event_0_time_batch      │ 144.05 KiB │ 8900 │
│ event_0_date_batch      │ 416.81 KiB │ 8900 │
│ event_0_time_func_batch │ 142.65 KiB │ 8900 │
│ event_0_date_single     │ 308.38 KiB │ 1780 │
└─────────────────────────┴────────────┴──────┴

2018-12-16 15:13:16 - table: event_0_date_batch - inserted: 8900 - took: 168.58 - bulk size: 5 - events per day: 25 - workers: 10
2018-12-16 15:18:52 - table: event_0_date_single - inserted: 1780 - took: 166.67 - bulk size: 1 - events per day: 5 - workers: 10
2018-12-16 15:25:06 - table: event_0_time_batch - inserted: 8900 - took: 155.42 - bulk size: 5 - events per day: 25 - workers: 10
2018-12-16 15:29:01 - table: event_0_time_func_batch - inserted: 8900 - took: 159.49 - bulk size: 5 - events per day: 25 - workers: 10

SELECT count() from event_0_time_batch group by toYYYYMM(time) 2.677s 2.240s 3.273s
SELECT count() from event_0_date_batch group by toYYYYMM(date) 2.219s 1.797s 2.073s
SELECT count() from event_0_time_func_batch group by toYYYYMM(time) 0.250s 0.159s 0.147s

SUMMARY: seems don't have to use date anymore (used to have to like us) https://github.com/yandex/ClickHouse/issues/2802