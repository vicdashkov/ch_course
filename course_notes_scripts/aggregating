CREATE DATABASE aggregating

CREATE TABLE aggregating.event
(
  id UInt64,
  time DateTime,
  type UInt16,
  pokemon_id UInt16
)
ENGINE = MergeTree()
PARTITION BY toYYYYMM(time)
ORDER BY (toYYYYMM(time), id);

lets start simple.
insert into event values(1, '2018-01-01 00:00:00', 1, 1);
insert into event values(1, '2018-01-01 00:00:00', 2, 1);
insert into event values(1, '2018-01-01 00:00:00', 2, 1);

now we can do
SELECT sumIf(type, type = 2)
FROM event
┌─sumIf(type, equals(type, 2))─┐
│                            4 │
└──────────────────────────────┘
or
SELECT countIf(type = 2)
FROM event
┌─countIf(equals(type, 2))─┐
│                        2 │
└──────────────────────────┘
simple enough
Lets explore state
SELECT countIfState(type = 2)
FROM event
┌─countIfState(equals(type, 2))─┐
│                               │
└───────────────────────────────┘
Make sense, and now
SELECT countIfMerge(x)
FROM
(
    SELECT countIfState(type = 2) AS x
    FROM event
)
┌─countIfMerge(x)─┐
│               2 │
└─────────────────┘

In production we want to create something like this
CREATE MATERIALIZED VIEW aggregating.event_aggs
ENGINE = AggregatingMergeTree()
PARTITION BY toYYYYMM(time)
ORDER BY (toYYYYMM(time), id)
AS SELECT
    id,
    time,
    sumState(type)    AS types_sum,
    uniqState(pokemon_id) AS unique_id
FROM aggregating.event
GROUP BY id, time;

quickly check
insert into event values(2, '2018-01-02 00:00:00', 1, 1);
insert into event values(2, '2018-01-02 00:00:00', 2, 1);
insert into event values(2, '2018-01-02 00:00:00', 2, 1);

select * from event where id=2
┌─id─┬────────────────time─┬─type─┬─pokemon_id─┐
│  2 │ 2018-01-02 00:00:00 │    1 │          1 │
│  2 │ 2018-01-02 00:00:00 │    2 │          1 │
│  2 │ 2018-01-02 00:00:00 │    2 │          1 │
└────┴─────────────────────┴──────┴────────────┘

And
SELECT
    sumMerge(types_sum),
    uniqMerge(unique_id)
FROM event_aggs
┌─sumMerge(types_sum)─┬─uniqMerge(unique_id)─┐
│                   5 │                    1 │
└─────────────────────┴──────────────────────┘

Ok, lets insert some data and do benchmarking with our selecter
config for inserter
TABLE_NAME = "event"
BULK_SIZE = 1000
EVENTS_PER_DAY = 1000
WORKERS = 5
DB_NAME = "aggregating"


def generate_random_event(event_date: datetime.datetime) -> dict:
    event_id = random.randint(0, 10)
    event_type = random.randint(0, 3)
    pokemon_id = random.randint(0, 10)
    event_datetime = event_date.replace(
        hour=random.randint(0, 23),
        minute=random.randint(0, 59))

    return {
        "id": event_id,
        "time": event_datetime,
        "type": event_type,
        "pokemon_id": pokemon_id
    }

benchmarking event.
SELECT sum(type) FROM aggregating.event
 attempt 0 took: 0.24256s
 attempt 1 took: 0.11743s
 attempt 2 took: 0.14443s

SELECT sumMerge(types_sum) FROM aggregating.event_aggs
 attempt 0 took: 0.21557s
 attempt 1 took: 0.1241s
 attempt 2 took: 0.16787s

TODO: bigger dataset; use other partition on work laptop

TODO: maybe?
SELECT sumForEach(x)
FROM
(
    SELECT [1, 2] AS x
    UNION ALL
    SELECT [3, 4, 5]
    UNION ALL
    SELECT [6, 7]
)
┌─sumForEach(x)─┐
│ [10,13,5]     │
└───────────────┘