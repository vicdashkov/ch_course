Preparation:
* pull down all dockers
* code editor scrips - code editor project files - slides
* start ch in backgroud
* setup inserter config

DO: demonstrate SHOW PROCESSLIST

Hello everyone,
In this lesson we'll talk about merge-tree family of CH engines

CH team reccomends using engines of this family pretty much for most tasks
They say those engines are the most advanced and feature reach
and data replication is possible only with engines from this family

There are other engines as well, and we'll talk about them in due time, but chances are
you'll start with some kind of merge tree table and stick to it for a long time

Let's connect to our newly configured ch instance
and try to create a table and a database

I was tempted to create a table like so at first. cool kinds don't read the docs, ha
But yeah this will fail

and the reason why it fails is that we need to let CH know about
some of the configs for this table
These configs will be the main focus of this lecture

If we look at called experimet_tables.sql
that you'll find in course files, you'll notice that there are of course different
ways to setup partitionain and order by for our tables

and I've seen people use date column for partition,
This seems to be not the best idea for CH, because it like to have pretty sparse indexes
so essentially we'd have to store 2 date columns: time and date.
Now documentation is pretty clear on it, but in older days this was what people did
and they are stuck with it on production

We will benchmark different setup and then try to make sense of it
I'be prepared different combinations for paprtitioning and order by in this
in the file called experiment_tables.sql, which you'll find in course files

It's about time I intorduce you to 2 small scripts to kind of dirty
benchmark our tables:
TODO: LINK TO REPO

ok. I'll run the test and we'll come back to results once it's done

-- from https://gist.github.com/sanchezzzhak/511fd140e8809857f8f1d84ddb937015
SELECT table, formatReadableSize(size) as size, rows, days, formatReadableSize(avgDaySize) as avgDaySize FROM (
    SELECT
        table,
        sum(bytes) AS size,
        sum(rows) AS rows
    FROM system.parts
    WHERE active
    GROUP BY table
    ORDER BY rows DESC
)

┌─table───────────────────┬─size───────┬─rows─┬
│ event_0_time_batch      │ 144.05 KiB │ 8900 │
│ event_0_date_batch      │ 416.81 KiB │ 8900 │
│ event_0_time_func_batch │ 142.65 KiB │ 8900 │
│ event_0_date_single     │ 308.38 KiB │ 1780 │
└─────────────────────────┴────────────┴──────┴

2018-12-16 15:13:16 - table: event_0_date_batch - inserted: 8900 - took: 168.58 - bulk size: 5 - events per day: 25 - workers: 10
2018-12-16 15:18:52 - table: event_0_date_single - inserted: 1780 - took: 166.67 - bulk size: 1 - events per day: 5 - workers: 10
2018-12-16 15:25:06 - table: event_0_time_batch - inserted: 8900 - took: 155.42 - bulk size: 5 - events per day: 25 - workers: 10
2018-12-16 15:29:01 - table: event_0_time_func_batch - inserted: 8900 - took: 159.49 - bulk size: 5 - events per day: 25 - workers: 10

SELECT count() from event_0_time_batch group by toYYYYMM(time) 2.677s 2.240s 3.273s
SELECT count() from event_0_date_batch group by toYYYYMM(date) 2.219s 1.797s 2.073s
SELECT count() from event_0_time_func_batch group by toYYYYMM(time) 0.250s 0.159s 0.147s

SUMMARY: seems don't have to use date anymore (used to have to like us) https://github.com/yandex/ClickHouse/issues/2802
and please don't use single inserts
actually i've seen very weird behaviour from ch with many single inserts. you can kill
you server easy