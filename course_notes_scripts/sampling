Preparation:
* rm data dir
* rm preprocessed configs
* slides
* browser tabix
* vs with inserter
* vs with course notes
* activate venv for selecter

Welcome back everyone.

Sometimes we all have a lot of data to process. khm
Which is all well and good. But not always do we have ram to process it.

Ch has an answer here
If we enable sampling on our table, we can save on RAM quite a bit,
since CH will perform your query on a small subset of our data.

ok. lets start by creating regular table

-- swithc to tabix

-- fastworward til execute all commands

ok so what we saw is of course regular select works,
But sampling not so much.
To fix it, we need to of course enable sampling

let's fix it with proper sampling table

-- switch to tabix tab 2

Now when we select from this table ch will return an evenly pseudorandom data sample
ok sort of makes sense. let's benchmark a bit

-- switch to tab 3

lets create benchmarking tables

and lets run our inserter and selecter,
We've seen them in action, so we know what to expecte, I'll just note that
I've changed configs accordingly with new dbs and table names

-- switch to users.xml

Before we do though, please note that I enabled query log for my user,
It will enable us to compare memory usage for queries

with command like

-- switch to tabix tab 4

So I put 365000000 events to our tables beforehand, and results are as follows

TODO: discuss the results
